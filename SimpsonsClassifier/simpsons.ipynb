{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from torchmetrics.classification import MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "\n",
    "\n",
    "train_dataset_path = \"./SimpsonsDataset/train\"\n",
    "val_dataset_path = \"./SimpsonsDataset/val\"\n",
    "test_dataset_path = \"./SimpsonsDataset/test\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Просмотр кол-ва изображений на класс\n",
    "\n",
    "Просмотрев кол-во сэмплов для каждого класса, можем сделать вывод, что датасет плохо сбалансирован, т.к. между классами разница в кол-ве сэмплов достигает сотен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "cletus_spuckler: 50 images\n",
      "lionel_hutz: 50 images\n",
      "agnes_skinner: 51 images\n",
      "martin_prince: 51 images\n",
      "patty_bouvier: 52 images\n",
      "professor_john_frink: 52 images\n",
      "rainier_wolfcastle: 52 images\n",
      "sideshow_mel: 52 images\n",
      "snake_jailbird: 54 images\n",
      "otto_mann: 58 images\n",
      "disco_stu: 59 images\n",
      "gil: 59 images\n",
      "miss_hoover: 59 images\n",
      "fat_tony: 61 images\n",
      "troy_mcclure: 61 images\n",
      "ralph_wiggum: 64 images\n",
      "carl_carlson: 70 images\n",
      "selma_bouvier: 75 images\n",
      "barney_gumble: 77 images\n",
      "groundskeeper_willie: 90 images\n",
      "maggie_simpson: 92 images\n",
      "waylon_smithers: 131 images\n",
      "mayor_quimby: 177 images\n",
      "lenny_leonard: 223 images\n",
      "nelson_muntz: 259 images\n",
      "edna_krabappel: 329 images\n",
      "comic_book_guy: 338 images\n",
      "kent_brockman: 358 images\n",
      "apu_nahasapeemapetilon: 448 images\n",
      "sideshow_bob: 632 images\n",
      "abraham_grampa_simpson: 658 images\n",
      "chief_wiggum: 710 images\n",
      "milhouse_van_houten: 777 images\n",
      "charles_montgomery_burns: 860 images\n",
      "principal_skinner: 860 images\n",
      "krusty_the_clown: 869 images\n",
      "marge_simpson: 930 images\n",
      "bart_simpson: 967 images\n",
      "lisa_simpson: 976 images\n",
      "moe_szyslak: 1046 images\n",
      "ned_flanders: 1047 images\n",
      "homer_simpson: 1617 images\n"
     ]
    }
   ],
   "source": [
    "def characters_count(dataset_path):\n",
    "    \"\"\"Подсчитывает кол-во сэмплов на каждый класс\"\"\"\n",
    "    character_count = {}\n",
    "\n",
    "    for character in os.listdir(dataset_path):\n",
    "        character_path = os.path.join(dataset_path, character)\n",
    "        num_files = len(os.listdir(character_path))\n",
    "        character_count[character] = num_files\n",
    "        \n",
    "    return character_count\n",
    "        \n",
    "cls_cnt = characters_count(train_dataset_path)\n",
    "print(len(cls_cnt))\n",
    "sorted_counts = sorted(cls_cnt.items(), key=lambda x: x[1])\n",
    "for character, count in sorted_counts:\n",
    "    print(f\"{character}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рассчет весов классов и сэмплов для балансировки данных\n",
    "\n",
    "При обучении нейросети на плохо сбалансированных данных, нейросеть будет отдавать предпочтение классам с большим кол-вом сэмплов. Чтобы это исправить мы можем использовать **WeightedRandomSampler**, который позволит пропорцианально выбирать сэмплы на основе их весов. Таким образом сэмплы из малочисленных классов получают большие веса и соответсвтенно большую вероятность выбора, а из многочисленных классов - меньшую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homer_simpson: 0.0006\n",
      "ned_flanders: 0.0010\n",
      "moe_szyslak: 0.0010\n",
      "lisa_simpson: 0.0010\n",
      "bart_simpson: 0.0010\n",
      "marge_simpson: 0.0011\n",
      "krusty_the_clown: 0.0012\n",
      "charles_montgomery_burns: 0.0012\n",
      "principal_skinner: 0.0012\n",
      "milhouse_van_houten: 0.0013\n",
      "chief_wiggum: 0.0014\n",
      "abraham_grampa_simpson: 0.0015\n",
      "sideshow_bob: 0.0016\n",
      "apu_nahasapeemapetilon: 0.0022\n",
      "kent_brockman: 0.0028\n",
      "comic_book_guy: 0.0030\n",
      "edna_krabappel: 0.0030\n",
      "nelson_muntz: 0.0039\n",
      "lenny_leonard: 0.0045\n",
      "mayor_quimby: 0.0056\n",
      "waylon_smithers: 0.0076\n",
      "maggie_simpson: 0.0109\n",
      "groundskeeper_willie: 0.0111\n",
      "barney_gumble: 0.0130\n",
      "selma_bouvier: 0.0133\n",
      "carl_carlson: 0.0143\n",
      "ralph_wiggum: 0.0156\n",
      "fat_tony: 0.0164\n",
      "troy_mcclure: 0.0164\n",
      "disco_stu: 0.0169\n",
      "gil: 0.0169\n",
      "miss_hoover: 0.0169\n",
      "otto_mann: 0.0172\n",
      "snake_jailbird: 0.0185\n",
      "patty_bouvier: 0.0192\n",
      "professor_john_frink: 0.0192\n",
      "rainier_wolfcastle: 0.0192\n",
      "sideshow_mel: 0.0192\n",
      "agnes_skinner: 0.0196\n",
      "martin_prince: 0.0196\n",
      "cletus_spuckler: 0.0200\n",
      "lionel_hutz: 0.0200\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(class_counts):\n",
    "    \"\"\"Рассчет весов для каждого класса\"\"\"\n",
    "    class_weights = {}\n",
    "\n",
    "    for cls, count in class_counts.items():\n",
    "        class_weights[cls] = 1 / count\n",
    "\n",
    "    return class_weights\n",
    "\n",
    "def compute_sample_weights(class_counts):\n",
    "    \"\"\"Подсчитывает веса для сэмплов в каждом классе\"\"\"\n",
    "    sample_weights = []\n",
    "\n",
    "    for character in os.listdir(train_dataset_path):\n",
    "        character_path = os.path.join(train_dataset_path, character)\n",
    "        num_files = len(os.listdir(character_path))\n",
    "\n",
    "        weight = 1 / num_files\n",
    "        sample_weights.extend([weight] * num_files)\n",
    "        \n",
    "    return torch.tensor(sample_weights, dtype=torch.float).to(device)\n",
    "\n",
    "sample_weights = compute_sample_weights(cls_cnt)\n",
    "\n",
    "class_weights = compute_class_weights(cls_cnt)\n",
    "sorted_weights = sorted(class_weights.items(), key=lambda x: x[1])\n",
    "for cls, weight in sorted_weights:\n",
    "    print(f\"{cls}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аугментации данных\n",
    "\n",
    "Аугментации позволят создать больше примеров для обучения путем случайных изменений изображений. Помимо того, что это помогает создавать больше сэмплов для малочисленных классов, аугментации так же улучшают обобщающие способности модели, делая ее более устойчивой к меняющимся условиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(is_train=False):\n",
    "    \"\"\"Предобработка изображений\n",
    "    \n",
    "        is_train = True: Добавляет аугментации во время обучения\n",
    "        \n",
    "        is_tain = False: Обычная предобработка\n",
    "    \"\"\"\n",
    "    if is_train:\n",
    "        return T.Compose([\n",
    "            T.Resize((224, 224)),            \n",
    "            T.RandomHorizontalFlip(),        \n",
    "            T.RandomResizedCrop(224, scale=(0.8, 1.0)),  \n",
    "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            T.RandomRotation(degrees=15),\n",
    "            T.ToTensor(),      \n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        return T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Используем модель ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImageFolder(root=train_dataset_path, transform=get_transforms(is_train=True))\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "train_loader = DataLoader(train_set, batch_size=128, sampler=sampler, num_workers=4)\n",
    "\n",
    "val_set = ImageFolder(root=val_dataset_path,transform=get_transforms(is_train=False))\n",
    "val_loader = DataLoader(val_set, batch_size=128,shuffle=False, num_workers=4)\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, child in model.named_children():\n",
    "    if name in ['layer4','fc']:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "num_classes = len(cls_cnt)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 11\n",
    "\n",
    "num_classes = len(cls_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировочный цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/11], Train Loss: 2.3407, Train Accuracy: 50.79%, Val loss: 1.3902, Val accuracy: 73.65, Val f1-score: 0.622467\n",
      "Epoch [2/11], Train Loss: 0.8840, Train Accuracy: 84.97%, Val loss: 0.7818, Val accuracy: 85.20, Val f1-score: 0.752839\n",
      "Epoch [3/11], Train Loss: 0.4900, Train Accuracy: 91.63%, Val loss: 0.5388, Val accuracy: 89.09, Val f1-score: 0.816090\n",
      "Epoch [4/11], Train Loss: 0.3337, Train Accuracy: 94.05%, Val loss: 0.4411, Val accuracy: 91.00, Val f1-score: 0.858145\n",
      "Epoch [5/11], Train Loss: 0.2407, Train Accuracy: 95.73%, Val loss: 0.3692, Val accuracy: 91.76, Val f1-score: 0.871899\n",
      "Epoch [6/11], Train Loss: 0.1850, Train Accuracy: 96.68%, Val loss: 0.3245, Val accuracy: 92.98, Val f1-score: 0.891713\n",
      "Epoch [7/11], Train Loss: 0.1552, Train Accuracy: 97.07%, Val loss: 0.3055, Val accuracy: 93.33, Val f1-score: 0.892583\n",
      "Epoch [8/11], Train Loss: 0.1296, Train Accuracy: 97.61%, Val loss: 0.2967, Val accuracy: 93.44, Val f1-score: 0.892217\n",
      "Epoch [9/11], Train Loss: 0.1052, Train Accuracy: 98.12%, Val loss: 0.2908, Val accuracy: 93.27, Val f1-score: 0.895101\n",
      "Epoch [10/11], Train Loss: 0.0953, Train Accuracy: 98.18%, Val loss: 0.2750, Val accuracy: 93.73, Val f1-score: 0.901116\n",
      "Epoch [11/11], Train Loss: 0.0886, Train Accuracy: 98.29%, Val loss: 0.2639, Val accuracy: 94.25, Val f1-score: 0.909205\n"
     ]
    }
   ],
   "source": [
    "val_f1_metric = MulticlassF1Score(num_classes=num_classes, average=\"macro\").to(device)\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data,dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_f1_metric.reset()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            val_f1_metric.update(predicted, labels)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_f1 = val_f1_metric.compute().item()\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], \"f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%, Val loss: {val_loss:.4f}, Val accuracy: {val_accuracy:.2f}, Val f1-score: {val_f1:2f}\")\n",
    "\n",
    "    \n",
    "torch.save(model.state_dict(), \"simpsons_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка точности модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.82%\n",
      "Class: abraham_grampa_simpson\n",
      " Precision: 0.9500\n",
      " Recall: 0.9396\n",
      " F1-score: 0.9448\n",
      "\n",
      "Class: agnes_skinner\n",
      " Precision: 1.0000\n",
      " Recall: 0.9286\n",
      " F1-score: 0.9630\n",
      "\n",
      "Class: apu_nahasapeemapetilon\n",
      " Precision: 0.9297\n",
      " Recall: 0.9597\n",
      " F1-score: 0.9444\n",
      "\n",
      "Class: barney_gumble\n",
      " Precision: 0.7778\n",
      " Recall: 0.6667\n",
      " F1-score: 0.7179\n",
      "\n",
      "Class: bart_simpson\n",
      " Precision: 0.9843\n",
      " Recall: 0.9366\n",
      " F1-score: 0.9598\n",
      "\n",
      "Class: carl_carlson\n",
      " Precision: 0.9444\n",
      " Recall: 0.8500\n",
      " F1-score: 0.8947\n",
      "\n",
      "Class: charles_montgomery_burns\n",
      " Precision: 0.9109\n",
      " Recall: 0.9454\n",
      " F1-score: 0.9278\n",
      "\n",
      "Class: chief_wiggum\n",
      " Precision: 0.9541\n",
      " Recall: 0.9492\n",
      " F1-score: 0.9517\n",
      "\n",
      "Class: cletus_spuckler\n",
      " Precision: 0.7647\n",
      " Recall: 0.9286\n",
      " F1-score: 0.8387\n",
      "\n",
      "Class: comic_book_guy\n",
      " Precision: 0.8947\n",
      " Recall: 0.9140\n",
      " F1-score: 0.9043\n",
      "\n",
      "Class: disco_stu\n",
      " Precision: 0.8889\n",
      " Recall: 0.9412\n",
      " F1-score: 0.9143\n",
      "\n",
      "Class: edna_krabappel\n",
      " Precision: 0.9362\n",
      " Recall: 0.9670\n",
      " F1-score: 0.9514\n",
      "\n",
      "Class: fat_tony\n",
      " Precision: 0.8947\n",
      " Recall: 1.0000\n",
      " F1-score: 0.9444\n",
      "\n",
      "Class: gil\n",
      " Precision: 0.7895\n",
      " Recall: 0.9375\n",
      " F1-score: 0.8571\n",
      "\n",
      "Class: groundskeeper_willie\n",
      " Precision: 0.9048\n",
      " Recall: 0.9048\n",
      " F1-score: 0.9048\n",
      "\n",
      "Class: homer_simpson\n",
      " Precision: 0.9336\n",
      " Recall: 0.9087\n",
      " F1-score: 0.9210\n",
      "\n",
      "Class: kent_brockman\n",
      " Precision: 0.9800\n",
      " Recall: 0.9899\n",
      " F1-score: 0.9849\n",
      "\n",
      "Class: krusty_the_clown\n",
      " Precision: 0.9549\n",
      " Recall: 0.9668\n",
      " F1-score: 0.9608\n",
      "\n",
      "Class: lenny_leonard\n",
      " Precision: 0.9333\n",
      " Recall: 0.9032\n",
      " F1-score: 0.9180\n",
      "\n",
      "Class: lionel_hutz\n",
      " Precision: 0.9231\n",
      " Recall: 0.8571\n",
      " F1-score: 0.8889\n",
      "\n",
      "Class: lisa_simpson\n",
      " Precision: 0.9585\n",
      " Recall: 0.9407\n",
      " F1-score: 0.9495\n",
      "\n",
      "Class: maggie_simpson\n",
      " Precision: 0.6389\n",
      " Recall: 0.8846\n",
      " F1-score: 0.7419\n",
      "\n",
      "Class: marge_simpson\n",
      " Precision: 0.9878\n",
      " Recall: 0.9419\n",
      " F1-score: 0.9643\n",
      "\n",
      "Class: martin_prince\n",
      " Precision: 0.6667\n",
      " Recall: 0.8571\n",
      " F1-score: 0.7500\n",
      "\n",
      "Class: mayor_quimby\n",
      " Precision: 0.8800\n",
      " Recall: 0.8980\n",
      " F1-score: 0.8889\n",
      "\n",
      "Class: milhouse_van_houten\n",
      " Precision: 0.9598\n",
      " Recall: 0.9954\n",
      " F1-score: 0.9773\n",
      "\n",
      "Class: miss_hoover\n",
      " Precision: 0.8667\n",
      " Recall: 0.8125\n",
      " F1-score: 0.8387\n",
      "\n",
      "Class: moe_szyslak\n",
      " Precision: 0.9195\n",
      " Recall: 0.9448\n",
      " F1-score: 0.9320\n",
      "\n",
      "Class: ned_flanders\n",
      " Precision: 0.9381\n",
      " Recall: 0.9381\n",
      " F1-score: 0.9381\n",
      "\n",
      "Class: nelson_muntz\n",
      " Precision: 0.8533\n",
      " Recall: 0.9143\n",
      " F1-score: 0.8828\n",
      "\n",
      "Class: otto_mann\n",
      " Precision: 1.0000\n",
      " Recall: 0.8125\n",
      " F1-score: 0.8966\n",
      "\n",
      "Class: patty_bouvier\n",
      " Precision: 0.6875\n",
      " Recall: 0.8462\n",
      " F1-score: 0.7586\n",
      "\n",
      "Class: principal_skinner\n",
      " Precision: 0.9657\n",
      " Recall: 0.9454\n",
      " F1-score: 0.9554\n",
      "\n",
      "Class: professor_john_frink\n",
      " Precision: 0.8667\n",
      " Recall: 0.9286\n",
      " F1-score: 0.8966\n",
      "\n",
      "Class: rainier_wolfcastle\n",
      " Precision: 0.9333\n",
      " Recall: 1.0000\n",
      " F1-score: 0.9655\n",
      "\n",
      "Class: ralph_wiggum\n",
      " Precision: 1.0000\n",
      " Recall: 1.0000\n",
      " F1-score: 1.0000\n",
      "\n",
      "Class: selma_bouvier\n",
      " Precision: 1.0000\n",
      " Recall: 0.7000\n",
      " F1-score: 0.8235\n",
      "\n",
      "Class: sideshow_bob\n",
      " Precision: 0.9942\n",
      " Recall: 0.9714\n",
      " F1-score: 0.9827\n",
      "\n",
      "Class: sideshow_mel\n",
      " Precision: 0.8125\n",
      " Recall: 0.9286\n",
      " F1-score: 0.8667\n",
      "\n",
      "Class: snake_jailbird\n",
      " Precision: 0.9167\n",
      " Recall: 0.7333\n",
      " F1-score: 0.8148\n",
      "\n",
      "Class: troy_mcclure\n",
      " Precision: 0.8500\n",
      " Recall: 1.0000\n",
      " F1-score: 0.9189\n",
      "\n",
      "Class: waylon_smithers\n",
      " Precision: 0.9143\n",
      " Recall: 0.8889\n",
      " F1-score: 0.9014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set = ImageFolder(root=test_dataset_path, transform=get_transforms(is_train=False))\n",
    "test_loader = DataLoader(test_set, batch_size=128, num_workers=4, shuffle=False)\n",
    "model.load_state_dict(torch.load(\"simpsons_model.pth\"))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "f1_metric = MulticlassF1Score(num_classes=num_classes, average=None).to(device)\n",
    "precision_metric = MulticlassPrecision(num_classes=num_classes, average=None).to(device)\n",
    "recall_metric = MulticlassRecall(num_classes=num_classes, average=None).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data,dim=1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        precision_metric.update(predicted, labels)\n",
    "        recall_metric.update(predicted, labels)\n",
    "        f1_metric.update(predicted, labels)\n",
    "\n",
    "precision = precision_metric.compute()\n",
    "recall = recall_metric.compute()\n",
    "f1 = f1_metric.compute()\n",
    "\n",
    "accuracy = 100 * correct/total\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "for i, cls in enumerate(test_set.classes):\n",
    "    print(f\"Class: {cls}\")\n",
    "    print(f\" Precision: {precision[i].item():.4f}\")\n",
    "    print(f\" Recall: {recall[i].item():.4f}\")\n",
    "    print(f\" F1-score: {f1[i].item():.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
