{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "train_dataset_path = \"./SimpsonsDataset/train\"\n",
    "test_dataset_path = \"./SimpsonsDataset/test\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Просмотр кол-ва изображений на класс\n",
    "\n",
    "Просмотрев кол-во сэмплов для каждого класса, можем сделать вывод, что датасет плохо сбалансирован, т.к. между классами разница в кол-ве сэмплов достигает сотен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cletus_spuckler: 56 images\n",
      "lionel_hutz: 56 images\n",
      "agnes_skinner: 57 images\n",
      "martin_prince: 57 images\n",
      "patty_bouvier: 58 images\n",
      "professor_john_frink: 58 images\n",
      "rainier_wolfcastle: 58 images\n",
      "sideshow_mel: 58 images\n",
      "snake_jailbird: 60 images\n",
      "otto_mann: 64 images\n",
      "miss_hoover: 65 images\n",
      "disco_stu: 66 images\n",
      "gil: 66 images\n",
      "fat_tony: 68 images\n",
      "troy_mcclure: 68 images\n",
      "ralph_wiggum: 71 images\n",
      "carl_carlson: 78 images\n",
      "selma_bouvier: 83 images\n",
      "barney_gumble: 85 images\n",
      "groundskeeper_willie: 100 images\n",
      "maggie_simpson: 102 images\n",
      "waylon_smithers: 145 images\n",
      "mayor_quimby: 197 images\n",
      "lenny_leonard: 248 images\n",
      "nelson_muntz: 288 images\n",
      "edna_krabappel: 366 images\n",
      "comic_book_guy: 376 images\n",
      "kent_brockman: 398 images\n",
      "apu_nahasapeemapetilon: 498 images\n",
      "sideshow_bob: 702 images\n",
      "abraham_grampa_simpson: 731 images\n",
      "chief_wiggum: 789 images\n",
      "milhouse_van_houten: 863 images\n",
      "charles_montgomery_burns: 955 images\n",
      "principal_skinner: 956 images\n",
      "krusty_the_clown: 965 images\n",
      "marge_simpson: 1033 images\n",
      "bart_simpson: 1074 images\n",
      "lisa_simpson: 1084 images\n",
      "moe_szyslak: 1162 images\n",
      "ned_flanders: 1163 images\n",
      "homer_simpson: 1797 images\n"
     ]
    }
   ],
   "source": [
    "def characters_count(dataset_path):\n",
    "    \"\"\"Подсчитывает кол-во сэмплов на каждый класс\"\"\"\n",
    "    character_count = {}\n",
    "\n",
    "    for character in os.listdir(dataset_path):\n",
    "        character_path = os.path.join(dataset_path, character)\n",
    "        num_files = len(os.listdir(character_path))\n",
    "        character_count[character] = num_files\n",
    "        \n",
    "    return character_count\n",
    "        \n",
    "cls_cnt = characters_count(train_dataset_path)\n",
    "sorted_counts = sorted(cls_cnt.items(), key=lambda x: x[1])\n",
    "for character, count in sorted_counts:\n",
    "    print(f\"{character}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рассчет весов классов и сэмплов для балансировки данных\n",
    "\n",
    "При обучении нейросети на плохо сбалансированных данных, нейросеть будет отдавать предпочтение классам с большим кол-вом сэмплов. Чтобы это исправить мы можем использовать **WeightedRandomSampler**, который позволит пропорцианально выбирать сэмплы на основе их весов. Таким образом сэмплы из малочисленных классов получают большие веса и соответсвтенно большую вероятность выбора, а из многочисленных классов - меньшую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homer_simpson: 0.0006\n",
      "ned_flanders: 0.0009\n",
      "moe_szyslak: 0.0009\n",
      "lisa_simpson: 0.0009\n",
      "bart_simpson: 0.0009\n",
      "marge_simpson: 0.0010\n",
      "krusty_the_clown: 0.0010\n",
      "principal_skinner: 0.0010\n",
      "charles_montgomery_burns: 0.0010\n",
      "milhouse_van_houten: 0.0012\n",
      "chief_wiggum: 0.0013\n",
      "abraham_grampa_simpson: 0.0014\n",
      "sideshow_bob: 0.0014\n",
      "apu_nahasapeemapetilon: 0.0020\n",
      "kent_brockman: 0.0025\n",
      "comic_book_guy: 0.0027\n",
      "edna_krabappel: 0.0027\n",
      "nelson_muntz: 0.0035\n",
      "lenny_leonard: 0.0040\n",
      "mayor_quimby: 0.0051\n",
      "waylon_smithers: 0.0069\n",
      "maggie_simpson: 0.0098\n",
      "groundskeeper_willie: 0.0100\n",
      "barney_gumble: 0.0118\n",
      "selma_bouvier: 0.0120\n",
      "carl_carlson: 0.0128\n",
      "ralph_wiggum: 0.0141\n",
      "fat_tony: 0.0147\n",
      "troy_mcclure: 0.0147\n",
      "disco_stu: 0.0152\n",
      "gil: 0.0152\n",
      "miss_hoover: 0.0154\n",
      "otto_mann: 0.0156\n",
      "snake_jailbird: 0.0167\n",
      "patty_bouvier: 0.0172\n",
      "professor_john_frink: 0.0172\n",
      "rainier_wolfcastle: 0.0172\n",
      "sideshow_mel: 0.0172\n",
      "agnes_skinner: 0.0175\n",
      "martin_prince: 0.0175\n",
      "cletus_spuckler: 0.0179\n",
      "lionel_hutz: 0.0179\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(class_counts):\n",
    "    \"\"\"Рассчет весов для каждого класса\"\"\"\n",
    "    class_weights = {}\n",
    "\n",
    "    for cls, count in class_counts.items():\n",
    "        class_weights[cls] = 1 / count\n",
    "\n",
    "    return class_weights\n",
    "\n",
    "def compute_sample_weights(class_counts):\n",
    "    \"\"\"Подсчитывает веса для сэмплов в каждом классе\"\"\"\n",
    "    sample_weights = []\n",
    "\n",
    "    for character in os.listdir(train_dataset_path):\n",
    "        character_path = os.path.join(train_dataset_path, character)\n",
    "        num_files = len(os.listdir(character_path))\n",
    "\n",
    "        weight = 1 / num_files\n",
    "        sample_weights.extend([weight] * num_files)\n",
    "        \n",
    "    return torch.tensor(sample_weights, dtype=torch.float).to(device)\n",
    "\n",
    "sample_weights = compute_sample_weights(cls_cnt)\n",
    "\n",
    "class_weights = compute_class_weights(cls_cnt)\n",
    "sorted_weights = sorted(class_weights.items(), key=lambda x: x[1])\n",
    "for cls, weight in sorted_weights:\n",
    "    print(f\"{cls}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аугментации данных\n",
    "\n",
    "Аугментации позволят создать больше примеров для обучения путем случайных изменений изображений. Помимо того, что это помогает создавать больше сэмплов для малочисленных классов, аугментации так же улучшают обобщающие способности модели, делая ее более устойчивой к меняющимся условиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(is_train=False):\n",
    "    \"\"\"Предобработка изображений\n",
    "    \n",
    "        is_train = True: Добавляет аугментации во время обучения\n",
    "        \n",
    "        is_tain = False: Обычная предобработка\n",
    "    \"\"\"\n",
    "    if is_train:\n",
    "        return T.Compose([\n",
    "            T.Resize((224, 224)),            \n",
    "            T.RandomHorizontalFlip(),        \n",
    "            T.RandomResizedCrop(224, scale=(0.8, 1.0)),  \n",
    "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            T.RandomRotation(degrees=15),\n",
    "            T.ToTensor(),      \n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        return T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Используем модель ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImageFolder(root=train_dataset_path, transform=get_transforms(is_train=True))\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "train_loader = DataLoader(train_set, batch_size=128, sampler=sampler, num_workers=4)\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, child in model.named_children():\n",
    "    if name in ['layer4','fc']:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "num_classes = len(cls_cnt)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировочный цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.8602, Train Accuracy: 79.35%\n",
      "Epoch [2/10], Train Loss: 0.2629, Train Accuracy: 93.26%\n",
      "Epoch [3/10], Train Loss: 0.1995, Train Accuracy: 94.64%\n",
      "Epoch [4/10], Train Loss: 0.1541, Train Accuracy: 95.74%\n",
      "Epoch [5/10], Train Loss: 0.1287, Train Accuracy: 96.45%\n",
      "Epoch [6/10], Train Loss: 0.1150, Train Accuracy: 96.74%\n",
      "Epoch [7/10], Train Loss: 0.0982, Train Accuracy: 97.20%\n",
      "Epoch [8/10], Train Loss: 0.1002, Train Accuracy: 97.14%\n",
      "Epoch [9/10], Train Loss: 0.0838, Train Accuracy: 97.53%\n",
      "Epoch [10/10], Train Loss: 0.0841, Train Accuracy: 97.54%\n",
      "Training accuracy for class abraham_grampa_simpson: 91.92%, 3789/4122\n",
      "Training accuracy for class agnes_skinner: 97.72%, 4073/4168\n",
      "Training accuracy for class apu_nahasapeemapetilon: 94.01%, 3927/4177\n",
      "Training accuracy for class barney_gumble: 95.01%, 3944/4151\n",
      "Training accuracy for class bart_simpson: 90.77%, 3709/4086\n",
      "Training accuracy for class carl_carlson: 98.14%, 4068/4145\n",
      "Training accuracy for class charles_montgomery_burns: 89.00%, 3753/4217\n",
      "Training accuracy for class chief_wiggum: 92.51%, 3718/4019\n",
      "Training accuracy for class cletus_spuckler: 97.42%, 4044/4151\n",
      "Training accuracy for class comic_book_guy: 93.74%, 3775/4027\n",
      "Training accuracy for class disco_stu: 98.31%, 4009/4078\n",
      "Training accuracy for class edna_krabappel: 94.63%, 3861/4080\n",
      "Training accuracy for class fat_tony: 97.92%, 3958/4042\n",
      "Training accuracy for class gil: 96.95%, 3978/4103\n",
      "Training accuracy for class groundskeeper_willie: 95.81%, 3959/4132\n",
      "Training accuracy for class homer_simpson: 86.00%, 3593/4178\n",
      "Training accuracy for class kent_brockman: 96.57%, 3945/4085\n",
      "Training accuracy for class krusty_the_clown: 93.61%, 3724/3978\n",
      "Training accuracy for class lenny_leonard: 94.22%, 3926/4167\n",
      "Training accuracy for class lionel_hutz: 97.88%, 3929/4014\n",
      "Training accuracy for class lisa_simpson: 90.06%, 3650/4053\n",
      "Training accuracy for class maggie_simpson: 94.89%, 3878/4087\n",
      "Training accuracy for class marge_simpson: 92.70%, 3834/4136\n",
      "Training accuracy for class martin_prince: 97.07%, 4012/4133\n",
      "Training accuracy for class mayor_quimby: 92.99%, 3849/4139\n",
      "Training accuracy for class milhouse_van_houten: 93.13%, 3808/4089\n",
      "Training accuracy for class miss_hoover: 97.88%, 4108/4197\n",
      "Training accuracy for class moe_szyslak: 86.41%, 3579/4142\n",
      "Training accuracy for class ned_flanders: 89.90%, 3640/4049\n",
      "Training accuracy for class nelson_muntz: 90.35%, 3697/4092\n",
      "Training accuracy for class otto_mann: 98.75%, 4117/4169\n",
      "Training accuracy for class patty_bouvier: 96.67%, 3913/4048\n",
      "Training accuracy for class principal_skinner: 89.14%, 3669/4116\n",
      "Training accuracy for class professor_john_frink: 96.79%, 3887/4016\n",
      "Training accuracy for class rainier_wolfcastle: 97.97%, 4056/4140\n",
      "Training accuracy for class ralph_wiggum: 98.47%, 3978/4040\n",
      "Training accuracy for class selma_bouvier: 96.15%, 3874/4029\n",
      "Training accuracy for class sideshow_bob: 94.11%, 3740/3974\n",
      "Training accuracy for class sideshow_mel: 97.81%, 3967/4056\n",
      "Training accuracy for class snake_jailbird: 96.79%, 3923/4053\n",
      "Training accuracy for class troy_mcclure: 96.81%, 4040/4173\n",
      "Training accuracy for class waylon_smithers: 94.75%, 3969/4189\n"
     ]
    }
   ],
   "source": [
    "classes_correct = {cls: 0 for cls in cls_cnt.keys()}\n",
    "classes_total = {cls: 0 for cls in cls_cnt.keys()}\n",
    "model.train()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data,dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for label,prediction in zip(labels, predicted):\n",
    "            if label == prediction:\n",
    "                classes_correct[train_set.classes[label.item()]] += 1\n",
    "            classes_total[train_set.classes[label.item()]] += 1\n",
    "            \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], \"f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "for cls in classes_correct.keys():\n",
    "    class_accuracy = 100 * classes_correct[cls] / classes_total[cls]\n",
    "    print(f\"Training accuracy for class {cls}: {class_accuracy:.2f}%, {classes_correct[cls]}/{classes_total[cls]}\")\n",
    "    \n",
    "torch.save(model.state_dict(), \"simpsons_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка точности модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 93.28%\n",
      "Testing accuracy for class abraham_grampa_simpson: 95.60%, 174/182\n",
      "Testing accuracy for class agnes_skinner: 100.00%, 14/14\n",
      "Testing accuracy for class apu_nahasapeemapetilon: 94.35%, 117/124\n",
      "Testing accuracy for class barney_gumble: 85.71%, 18/21\n",
      "Testing accuracy for class bart_simpson: 91.04%, 244/268\n",
      "Testing accuracy for class carl_carlson: 95.00%, 19/20\n",
      "Testing accuracy for class charles_montgomery_burns: 92.44%, 220/238\n",
      "Testing accuracy for class chief_wiggum: 95.43%, 188/197\n",
      "Testing accuracy for class cletus_spuckler: 85.71%, 12/14\n",
      "Testing accuracy for class comic_book_guy: 91.40%, 85/93\n",
      "Testing accuracy for class disco_stu: 88.24%, 15/17\n",
      "Testing accuracy for class edna_krabappel: 92.31%, 84/91\n",
      "Testing accuracy for class fat_tony: 94.12%, 16/17\n",
      "Testing accuracy for class gil: 75.00%, 12/16\n",
      "Testing accuracy for class groundskeeper_willie: 80.95%, 17/21\n",
      "Testing accuracy for class homer_simpson: 88.64%, 398/449\n",
      "Testing accuracy for class kent_brockman: 98.99%, 98/99\n",
      "Testing accuracy for class krusty_the_clown: 96.68%, 233/241\n",
      "Testing accuracy for class lenny_leonard: 95.16%, 59/62\n",
      "Testing accuracy for class lionel_hutz: 92.86%, 13/14\n",
      "Testing accuracy for class lisa_simpson: 93.33%, 252/270\n",
      "Testing accuracy for class maggie_simpson: 96.15%, 25/26\n",
      "Testing accuracy for class marge_simpson: 95.35%, 246/258\n",
      "Testing accuracy for class martin_prince: 92.86%, 13/14\n",
      "Testing accuracy for class mayor_quimby: 83.67%, 41/49\n",
      "Testing accuracy for class milhouse_van_houten: 95.83%, 207/216\n",
      "Testing accuracy for class miss_hoover: 87.50%, 14/16\n",
      "Testing accuracy for class moe_szyslak: 97.24%, 282/290\n",
      "Testing accuracy for class ned_flanders: 96.56%, 281/291\n",
      "Testing accuracy for class nelson_muntz: 87.14%, 61/70\n",
      "Testing accuracy for class otto_mann: 81.25%, 13/16\n",
      "Testing accuracy for class patty_bouvier: 61.54%, 8/13\n",
      "Testing accuracy for class principal_skinner: 90.76%, 216/238\n",
      "Testing accuracy for class professor_john_frink: 92.86%, 13/14\n",
      "Testing accuracy for class rainier_wolfcastle: 92.86%, 13/14\n",
      "Testing accuracy for class ralph_wiggum: 100.00%, 18/18\n",
      "Testing accuracy for class selma_bouvier: 80.00%, 16/20\n",
      "Testing accuracy for class sideshow_bob: 97.14%, 170/175\n",
      "Testing accuracy for class sideshow_mel: 92.86%, 13/14\n",
      "Testing accuracy for class snake_jailbird: 93.33%, 14/15\n",
      "Testing accuracy for class troy_mcclure: 94.12%, 16/17\n",
      "Testing accuracy for class waylon_smithers: 88.89%, 32/36\n"
     ]
    }
   ],
   "source": [
    "classes_correct_test = {cls: 0 for cls in cls_cnt.keys()}\n",
    "classes_total_test = {cls: 0 for cls in cls_cnt.keys()}\n",
    "test_set = ImageFolder(root=test_dataset_path, transform=get_transforms(is_train=False))\n",
    "test_loader = DataLoader(test_set, batch_size=128, num_workers=4, shuffle=False)\n",
    "model.load_state_dict(torch.load(\"simpsons_model.pth\"))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data,dim=1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for label,prediction in zip(labels, predicted):\n",
    "            if label == prediction:\n",
    "                classes_correct_test[test_set.classes[label.item()]] += 1\n",
    "            classes_total_test[test_set.classes[label.item()]] += 1\n",
    "\n",
    "accuracy = 100 * correct/total\n",
    "print(f\"Average accuracy: {accuracy:.2f}%\")\n",
    "for cls in classes_correct_test.keys():\n",
    "    class_accuracy_test = 100 * classes_correct_test[cls] / classes_total_test[cls]\n",
    "    print(f\"Testing accuracy for class {cls}: {class_accuracy_test:.2f}%, {classes_correct_test[cls]}/{classes_total_test[cls]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
